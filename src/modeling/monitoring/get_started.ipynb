{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SB93Ge748VQs"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "0sK8X2O9bTlz"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEYuO5NFwDK9"
      },
      "source": [
        "# Get started with TensorBoard\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tensorboard/get_started\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/get_started.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/tensorboard/blob/master/docs/get_started.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/tensorboard/docs/get_started.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56V5oun18ZdZ"
      },
      "source": [
        "In machine learning, to improve something you often need to be able to measure it. TensorBoard is a tool for providing the measurements and visualizations needed during the machine learning workflow. It enables tracking experiment metrics like loss and accuracy, visualizing the model graph, projecting embeddings to a lower dimensional space, and much more.\n",
        "\n",
        "This quickstart will show how to quickly get started with TensorBoard. The remaining guides in this website provide more details on specific capabilities, many of which are not included here. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6B95Hb6YVgPZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.20.0\n"
          ]
        }
      ],
      "source": [
        "import tensorboard\n",
        "print(tensorboard.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Any process on port 6006 has been terminated.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stop-Process : Cannot stop process \"Idle (0)\" because of the following error: Access is denied\n",
            "At line:1 char:87\n",
            "+ ... ontinue | ForEach-Object { Stop-Process -Id $_.OwningProcess -Force }\n",
            "+                                ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "    + CategoryInfo          : CloseError: (System.Diagnostics.Process (Idle):Process) [Stop-Process], ProcessCommandEx \n",
            "   ception\n",
            "    + FullyQualifiedErrorId : CouldNotStopProcess,Microsoft.PowerShell.Commands.StopProcessCommand\n",
            " \n"
          ]
        }
      ],
      "source": [
        "# This command finds the Process ID (PID) using port 6006 and kills it\n",
        "!powershell -ExecutionPolicy Bypass -Command \"Get-NetTCPConnection -LocalPort 6007 -ErrorAction SilentlyContinue | ForEach-Object { Stop-Process -Id $_.OwningProcess -Force }\"\n",
        "\n",
        "print(\"✅ Any process on port 6006 has been terminated.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Directory exists! Files found: ['DQN_trading_run_1', 'DQN_trading_run_10', 'DQN_trading_run_11', 'DQN_trading_run_12', 'DQN_trading_run_13', 'DQN_trading_run_14', 'DQN_trading_run_15', 'DQN_trading_run_16', 'DQN_trading_run_17', 'DQN_trading_run_18', 'DQN_trading_run_19', 'DQN_trading_run_2', 'DQN_trading_run_3', 'DQN_trading_run_4', 'DQN_trading_run_5', 'DQN_trading_run_6', 'DQN_trading_run_7', 'DQN_trading_run_8', 'DQN_trading_run_9', 'monitor.csv', 'PPO_trading_run_1', 'PPO_trading_run_2', 'PPO_trading_run_3', 'PPO_trading_run_4']\n",
            "Opening TensorBoard with path: c:\\Users\\Sandeep\\Documents\\Work\\code\\claude-pattern-trading\\src\\monitoring\\logs\\tboard_rita_rl_logs\n",
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-f71c8c75a4cfae2b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-f71c8c75a4cfae2b\");\n",
              "          const url = new URL(\"/\", window.location);\n",
              "          const port = 6008;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "log_path = \"../../monitoring/logs/tboard_rita_rl_logs/\"\n",
        "if os.path.exists(log_path):\n",
        "    print(f\"✅ Directory exists! Files found: {os.listdir(log_path)}\")\n",
        "else:\n",
        "    print(f\"❌ Directory NOT found at {os.path.abspath(log_path)}\")\n",
        "\n",
        "# Get the absolute path automatically\n",
        "log_dir_abs = os.path.abspath(\"../../monitoring/logs/tboard_rita_rl_logs/\")\n",
        "\n",
        "print(f\"Opening TensorBoard with path: {log_dir_abs}\")\n",
        "\n",
        "%load_ext tensorboard\n",
        "# We use --port 6007 just in case 6006 is \"stuck\"\n",
        "%tensorboard --logdir \"{log_dir_abs}\" --port 6008"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 23416), started 1 day, 6:50:10 ago. (Use '!kill 23416' to kill it.)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-d64c6d8b975ed59e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-d64c6d8b975ed59e\");\n",
              "          const url = new URL(\"http://localhost\");\n",
              "          const port = 6006;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Use ../ to move up levels in the directory tree\n",
        "# %load_ext tensorboard\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir ../../monitoring/logs/tboard_rita_rl_logs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_wqSAZExy6xV"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Sandeep\\Documents\\Work\\code\\claude-pattern-trading\\project-env\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(np, \"object\"):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.20.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ao7fJW1Pyiza"
      },
      "outputs": [],
      "source": [
        "# Clear any logs from previous runs\n",
        "# !rm -rf ./logs/ \n",
        "\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# This replaces \"!rm -rf ./logs/\"\n",
        "log_path = './logs/'\n",
        "if os.path.exists(log_path):\n",
        "    shutil.rmtree(log_path)\n",
        "    print(\"Logs cleared!\")\n",
        "else:\n",
        "    print(\"No logs found to delete.\")\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5pr9vuHVgXY"
      },
      "source": [
        "Using the [MNIST](https://en.wikipedia.org/wiki/MNIST_database) dataset as the example, normalize the data and write a function that creates a simple Keras model for classifying the images into 10 classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-DHsby18cot"
      },
      "outputs": [],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "def create_model():\n",
        "  return tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input(shape=(28, 28), name='layers_input'),\n",
        "    tf.keras.layers.Flatten(name='layers_flatten'),\n",
        "    tf.keras.layers.Dense(512, activation='relu', name='layers_dense'),\n",
        "    tf.keras.layers.Dropout(0.2, name='layers_dropout'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax', name='layers_dense_2')\n",
        "  ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKUjdIoV87um"
      },
      "source": [
        "## Using TensorBoard with Keras Model.fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CL_lxdn8-Sv"
      },
      "source": [
        "When training with Keras's [Model.fit()](https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#fit), adding the `tf.keras.callbacks.TensorBoard` callback ensures that logs are created and stored. Additionally, enable histogram computation every epoch with `histogram_freq=1` (this is off by default)\n",
        "\n",
        "Place the logs in a timestamped subdirectory to allow easy selection of different training runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAQThq539CEJ"
      },
      "outputs": [],
      "source": [
        "model = create_model()\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "model.fit(x=x_train, \n",
        "          y=y_train, \n",
        "          epochs=5, \n",
        "          validation_data=(x_test, y_test), \n",
        "          callbacks=[tensorboard_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asjGpmD09dRl"
      },
      "source": [
        "Start TensorBoard through the command line or within a notebook experience. The two interfaces are generally the same. In notebooks, use the `%tensorboard` line magic. On the command line, run the same command without \"%\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4UKgTLb9fKI"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs/fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCsoUNb6YhGc"
      },
      "source": [
        "<!-- <img class=\"tfo-display-only-on-site\" src=\"https://github.com/tensorflow/tensorboard/blob/master/docs/images/quickstart_model_fit.png?raw=1\"/> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi4PaRm39of2"
      },
      "source": [
        "A brief overview of the visualizations created in this example and the dashboards (tabs in top navigation bar) where they can be found:\n",
        "\n",
        "* **Scalars** show how the loss and metrics change with every epoch. You can use them to also track training speed, learning rate, and other scalar values. Scalars can be found in the **Time Series** or **Scalars** dashboards.\n",
        "* **Graphs** help you visualize your model. In this case, the Keras graph of layers is shown which can help you ensure it is built correctly. Graphs can be found in the **Graphs** dashboard.\n",
        "* **Histograms** and **Distributions** show the distribution of a Tensor over time. This can be useful to visualize weights and biases and verify that they are changing in an expected way. Histograms can be found in the **Time Series** or **Histograms** dashboards. Distributions can be found in the **Distributions** dashboard.\n",
        "\n",
        "Additional TensorBoard dashboards are automatically enabled when you log other types of data. For example, the Keras TensorBoard callback lets you log images and embeddings as well. You can see what other dashboards are available in TensorBoard by clicking on the \"inactive\" dropdown towards the top right."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nB718NOH95yG"
      },
      "source": [
        "## Using TensorBoard with other methods\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKNt0nWs-Ekt"
      },
      "source": [
        "When training with methods such as [`tf.GradientTape()`](https://www.tensorflow.org/api_docs/python/tf/GradientTape), use `tf.summary` to log the required information.\n",
        "\n",
        "Use the same dataset as above, but convert it to `tf.data.Dataset` to take advantage of batching capabilities:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnHx4DsMezy1"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "\n",
        "train_dataset = train_dataset.shuffle(60000).batch(64)\n",
        "test_dataset = test_dataset.batch(64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzpmTmJafJ10"
      },
      "source": [
        "The training code follows the [advanced quickstart](https://www.tensorflow.org/tutorials/quickstart/advanced) tutorial, but shows how to log metrics to TensorBoard. Choose loss and optimizer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2Y5-aPbAANs"
      },
      "outputs": [],
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKhIIDj9Hbfy"
      },
      "source": [
        "Create stateful metrics that can be used to accumulate values during training and logged at any point:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jD0tEWrgH0TL"
      },
      "outputs": [],
      "source": [
        "# Define our metrics\n",
        "train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('train_accuracy')\n",
        "test_loss = tf.keras.metrics.Mean('test_loss', dtype=tf.float32)\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('test_accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szw_KrgOg-OT"
      },
      "source": [
        "Define the training and test functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTWcJO35IJgK"
      },
      "outputs": [],
      "source": [
        "def train_step(model, optimizer, x_train, y_train):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(x_train, training=True)\n",
        "    loss = loss_object(y_train, predictions)\n",
        "  grads = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(y_train, predictions)\n",
        "\n",
        "def test_step(model, x_test, y_test):\n",
        "  predictions = model(x_test)\n",
        "  loss = loss_object(y_test, predictions)\n",
        "\n",
        "  test_loss(loss)\n",
        "  test_accuracy(y_test, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nucPZBKPJR3A"
      },
      "source": [
        "Set up summary writers to write the summaries to disk in a different logs directory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Qp-exmbWf4w"
      },
      "outputs": [],
      "source": [
        "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
        "test_log_dir = 'logs/gradient_tape/' + current_time + '/test'\n",
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
        "test_summary_writer = tf.summary.create_file_writer(test_log_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgUJgDdKWUKF"
      },
      "source": [
        "Start training. Use `tf.summary.scalar()` to log metrics (loss and accuracy) during training/testing within the scope of the summary writers to write the summaries to disk. You have control over which metrics to log and how often to do it. Other `tf.summary` functions enable logging other types of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odWvHPpKJvb_"
      },
      "outputs": [],
      "source": [
        "model = create_model() # reset our model\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  for (x_train, y_train) in train_dataset:\n",
        "    train_step(model, optimizer, x_train, y_train)\n",
        "  with train_summary_writer.as_default():\n",
        "    tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
        "    tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
        "\n",
        "  for (x_test, y_test) in test_dataset:\n",
        "    test_step(model, x_test, y_test)\n",
        "  with test_summary_writer.as_default():\n",
        "    tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
        "    tf.summary.scalar('accuracy', test_accuracy.result(), step=epoch)\n",
        "  \n",
        "  template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
        "  print (template.format(epoch+1,\n",
        "                         train_loss.result(), \n",
        "                         train_accuracy.result()*100,\n",
        "                         test_loss.result(), \n",
        "                         test_accuracy.result()*100))\n",
        "\n",
        "  # Reset metrics every epoch\n",
        "  train_loss.reset_state()\n",
        "  test_loss.reset_state()\n",
        "  train_accuracy.reset_state()\n",
        "  test_accuracy.reset_state()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JikosQ84fzcA"
      },
      "source": [
        "Open TensorBoard again, this time pointing it at the new log directory. We could have also started TensorBoard to monitor training while it progresses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Iue509kgOyE"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs/gradient_tape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%tensorboard --logdir ./monitoring/logs/tboard_rita_rl_logs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVpnilhEgQXk"
      },
      "source": [
        "<!-- <img class=\"tfo-display-only-on-site\" src=\"https://github.com/tensorflow/tensorboard/blob/master/docs/images/quickstart_gradient_tape.png?raw=1\"/> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozbwXgPIkCKV"
      },
      "source": [
        "That's it! You have now seen how to use TensorBoard both through the Keras callback and through `tf.summary` for more custom scenarios. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "get_started.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "project-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
